* Why Containers?

  * Isolate
    * bio-informatics pipelines will combine many different tools
    * each tool may be totally different languages/versions
    * each tool will have different installation and OS dependencies
    * trying to install more than one package onto one machine is messy
    * CAPS (Chef, Ansible, Puppet and Saltstack) try to do this
    * each container has it's own Mount Namespace (think 'isolated virtual disk')
    * this means each container (thinks it) has a brand new machine to install software onto

  * Expediate
    * pre-built immutable binary images (a.k.a. the Dockerhub) - 'docker pull' and done
    * VM's also have this (for example AMI images for EC2 instances)
    * the time to start a container is an order of magnitude quicker than a VM
    * because the kernel is shared between containers
    * VM startup time 30secs to several minutes
    * container startup time 10ms to 10secs

  * Compact
    * you can put many more containers onto a bare metal server than VMs
    * because you are not duplicating the entire OS kernel for each container
    * CGroups allow you to limit the resources used by a single container (CPU, Memory etc)
    * this allows fine grained control over "how much to fill up the boxes"

* Docker Storage

  * Images
    * when you build a Docker image - it uses the 'graph driver' to save each layer
    * a layer is the result of running a command on a previous layer
    * there are various 'graph drivers' - most use 'copy-on-write'
    * aufs, devicemapper, overlayfs (there is even a ZFS driver in the works)
    * whilst important - this is not the type of storage we are focusing on today

  * Dockerfile example without volume

  * Volumes
    * when a container runs (from an image) - it has it's own 'mount namespace'
    * this means that filesystem operations are isolated inside the container
    * but what if the container needs to read and write to disk?
    * a Docker volume is a bind-mounted directory from the host into a container
    * this means data written to that directory persists even when the container stops
    * because it's a shared kernel, you can use funky filesystems (ZFS, EBS, Fuse etc)
  
  * Dockerfile example with volume

  * Demo of Docker Volumes
    * no volume - the state is not there the next time
    * a named volume - now we know where the data is
    * multi-host volume - yikes, this needs some thought

* Servers

  * Naming servers
    * I used to name my servers
    * if one went away - it really mattered
    * each one was lovingly configured and had a specific set of jobs
    * I treated them like pets

  * Not naming servers
    * it turns out that computers are not like animals
    * they do not repay human kindess with affection (they fail randomly)
    * each server should be auto-configured and interchangeable
    * they should be treated like cattle

  * Don't touch that disk!
    * the moment you write anything to disk you make the server a pet
    * that is because no other server in the cluster has that data on it's disk
    * to truely treat servers like cattle - we need 'portable data volumes'
    * then we can loose a server and the data can be moved to another one

* Flocker

  * Volume orchestration
    * storage orchestration tool for a cluster of machines
    * aware of data-volumes and what host they live on
    * can move data-volumes alongside containers as a single, atomic unit
    * provides a REST API that can be used from any language or stack

  * Image of Flocker architecture

  * Backend storage drivers
    * supports a range of different backend storage drivers
    * choose the right backend dependent upon your use-case
    * Amazon EBS and OpenStack Cinder for network attached block devices
    * EMC scale.io and xtrem.io support
    * Hedvig, Converge.io and many others

  * Image of Flocker universe

  * Docker Plugin
    * plugins mechanism for Docker allows external processes to handle volumes
    * Docker --volume-driver syntax means Docker will call out to Flocker to handle a volume
    * when a container starts with a Flocker volume - Docker will block until the volume is mounted by Flocker
  
  * Image of Docker plugin

  * Demo of multi-host

* Orchestration

  * Hide the hardware
    * you have a 'pool of compute resources'
    * let's hide this away behind an orchestration tool
    * we tell the orchestrator what we want to happen
    * it knows how to get things into that state
    * think about your 'desired state' not individual computers

  * Scheduling
    * when you say 'run this process' something needs to decide where
    * schedulers needs to know what else is running on the cluster
    * they then play a game of Tetris to find the best place
  
  * Monitoring
    * orchestration tools can detect when a process dies or a host fails
    * they will 're-schedule' the process(es) onto a healthy machine
    * this is an automated version of 'drive to the data-centre at 3am'


  * Demo

* Questions

  * How do you deploy the code for bio-informatics pipelines?
  * Does this code run across more than one machine?
  * Where do you get the data from to process?
  * Where do you save the results of the pipeline?
  * Do intermediate processes need to use lookup tables or other databases?
  * summary: can we use the same tools that we use in DevOps for processing pipelines?

  